{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'customHelpers' from '/Users/nagibshah/dev/COMP5349_AmazonProductReviewAnalysis/notebooks/customHelpers.py'>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# library imports \n",
    "import sys\n",
    "from importlib import reload\n",
    "import findspark\n",
    "import customHelpers as helper\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import StructType, StructField, StringType,IntegerType, FloatType,BooleanType,DateType\n",
    "\n",
    "reload(helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the session \n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Amazon Product Review Analysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "#sc = SparkContext(appName=\"Amazon Product Review Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset \n",
    "\n",
    "| Column | Description | \n",
    "| :--- | :--- |\n",
    "| marketplace | 2 letter country code of the marketplace where the review was written. |\n",
    "| customer_id | Random identifier that can be used to aggregate reviews written by a single author. |\n",
    "| review_id | The unique ID of the review. |\n",
    "| product_id | The unique Product ID the review pertains to. In the multilingual dataset the reviews for the same product in different countries can be grouped by the same product_id. | \n",
    "| product_parent | Random identifier that can be used to aggregate reviews for the same product. |\n",
    "| product_title | Title of the product. | \n",
    "| product_category | Broad product category that can be used to group reviews (also used to group the dataset into  coherent parts). | \n",
    "| star_rating | the 1-5 star rating of the review. | \n",
    "| helpful_votes | Number of helpful votes. | \n",
    "| total_votes | Number of total votes the review received. | \n",
    "| vine | Review was written as part of the Vine program. |\n",
    "| verified_purchase | The review is on a verified purchase. |\n",
    "| review_headline | The title of the review. |\n",
    "| review_body | The review text. |\n",
    "| review_date | The date the review was written | \n",
    "\n",
    "\n",
    "DATA FORMAT\n",
    "Tab ('\\t') separated text file, without quote or escape characters.\n",
    "First line in each file is header; 1 line corresponds to 1 record.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.41 ms, sys: 1.29 ms, total: 3.69 ms\n",
      "Wall time: 1.22 s\n"
     ]
    }
   ],
   "source": [
    "# load the data set \n",
    "#review_data = '../data/sample_us.tsv'\n",
    "# actual data load - PERFORMANCE WARNING ON LOCAL MACHINE\n",
    "review_data = '../data/amazon_reviews_us_Music_v1_00.tsv'\n",
    "\n",
    "aws_product_review_schema = StructType([\n",
    "    StructField(\"marketplace\", StringType(), True),\n",
    "    StructField(\"customer_id\", StringType(), True),\n",
    "    StructField(\"review_id\", StringType(), True),\n",
    "    StructField(\"product_id\",StringType(),True),\n",
    "    StructField(\"product_parent\",StringType(),False),\n",
    "    StructField(\"product_title\", StringType(), False),\n",
    "    StructField(\"product_category\", StringType(), False),\n",
    "    StructField(\"star_rating\", IntegerType(), False),\n",
    "    StructField(\"helpful_votes\",IntegerType(),False),\n",
    "    StructField(\"total_votes\", IntegerType(), False),\n",
    "    StructField(\"vine\",StringType(),False),\n",
    "    StructField(\"verified_purchase\", StringType(), False),\n",
    "    StructField(\"review_headline\", StringType(), False),\n",
    "    StructField(\"review_body\", StringType(), False),\n",
    "    StructField(\"review_date\",DateType(),False)])\n",
    "\n",
    "aws_product_review_schema_limited = StructType([\n",
    "    StructField(\"customer_id\", StringType(), True),\n",
    "    StructField(\"review_id\", StringType(), True),\n",
    "    StructField(\"product_id\",StringType(),True),\n",
    "    StructField(\"product_title\", StringType(), False),\n",
    "    StructField(\"product_category\", StringType(), False),\n",
    "    StructField(\"star_rating\", IntegerType(), False),\n",
    "    StructField(\"helpful_votes\",IntegerType(),False),\n",
    "    StructField(\"total_votes\", IntegerType(), False),\n",
    "    StructField(\"review_headline\", StringType(), False),\n",
    "    StructField(\"review_body\", StringType(), False),\n",
    "    StructField(\"review_date\",DateType(),False)])\n",
    "\n",
    "%time awsProductReview_raw_data = spark.read.csv(review_data,header=True,sep=\"\\t\",schema=aws_product_review_schema)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4751577\n",
      "1000000\n"
     ]
    }
   ],
   "source": [
    "# when testing in local machine only \n",
    "print(awsProductReview_raw_data.count())\n",
    "# limit to 1 mil\n",
    "awsProductReview_raw_data = awsProductReview_raw_data.limit(1000000)\n",
    "print(awsProductReview_raw_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n",
      "|marketplace|customer_id|     review_id|product_id|product_parent|       product_title|product_category|star_rating|helpful_votes|total_votes|vine|verified_purchase|     review_headline|         review_body|review_date|\n",
      "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n",
      "|         US|   10140119|R3LI5TRP3YIDQL|B00TXH4OLC|     384427924|Whatever's for Us...|           Music|          5|            0|          0|   N|                Y|          Five Stars|Love this CD alon...| 2015-08-31|\n",
      "|         US|   27664622|R3LGC3EKEG84PX|B00B6QXN6U|     831769051|Same Trailer Diff...|           Music|          5|            0|          0|   N|                Y|A new fave in our...|This is the album...| 2015-08-31|\n",
      "|         US|   45946560| R9PYL3OYH55QY|B001GCZXW6|      14067376| Soaring (Jazz Club)|           Music|          5|            0|          1|   N|                Y|          Five Stars|  Excellent / thanks| 2015-08-31|\n",
      "|         US|   15146326|R3PWBAWUS4NT0Q|B000003EK6|     566295619|     CARIBBEAN PARTY|           Music|          3|            0|          0|   N|                Y|         Three Stars|Nice variety of c...| 2015-08-31|\n",
      "|         US|   16794688|R15LYP3O51UU9E|B00N1F0BKK|     210426072|         Pain Killer|           Music|          5|            0|          0|   N|                Y|          Five Stars|Purchased as a gi...| 2015-08-31|\n",
      "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "awsProductReview_raw_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+----------+--------------------+----------------+-----------+-------------+-----------+--------------------+--------------------+-----------+\n",
      "|customer_id|     review_id|product_id|       product_title|product_category|star_rating|helpful_votes|total_votes|     review_headline|         review_body|review_date|\n",
      "+-----------+--------------+----------+--------------------+----------------+-----------+-------------+-----------+--------------------+--------------------+-----------+\n",
      "|   10140119|R3LI5TRP3YIDQL|B00TXH4OLC|Whatever's for Us...|           Music|          5|            0|          0|          Five Stars|Love this CD alon...| 2015-08-31|\n",
      "|   27664622|R3LGC3EKEG84PX|B00B6QXN6U|Same Trailer Diff...|           Music|          5|            0|          0|A new fave in our...|This is the album...| 2015-08-31|\n",
      "|   45946560| R9PYL3OYH55QY|B001GCZXW6| Soaring (Jazz Club)|           Music|          5|            0|          1|          Five Stars|  Excellent / thanks| 2015-08-31|\n",
      "|   15146326|R3PWBAWUS4NT0Q|B000003EK6|     CARIBBEAN PARTY|           Music|          3|            0|          0|         Three Stars|Nice variety of c...| 2015-08-31|\n",
      "|   16794688|R15LYP3O51UU9E|B00N1F0BKK|         Pain Killer|           Music|          5|            0|          0|          Five Stars|Purchased as a gi...| 2015-08-31|\n",
      "+-----------+--------------+----------+--------------------+----------------+-----------+-------------+-----------+--------------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfProductReview = awsProductReview_raw_data.drop('vine').drop('verified_purchase') \\\n",
    "                    .drop('product_parent').drop('marketplace')\n",
    "dfProductReview.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows before filter: 1000000\n",
      "number of rows after filter: 999701\n"
     ]
    }
   ],
   "source": [
    "# remove rows with no review text \n",
    "print(\"number of rows before filter: {0}\".format(dfProductReview.count()))\n",
    "dfFilteredReviews = dfProductReview.na.drop(subset=[\"review_body\"])\n",
    "print(\"number of rows after filter: {0}\".format(dfFilteredReviews.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage One: Overall statistics\n",
    "\n",
    "### Produce overall summary statistics of the data set, in particular,\n",
    "\n",
    "* the total number of reviews\n",
    "* the number of unique users\n",
    "* the number of unique products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------+-------------+\n",
      "|unique_customers|unique_products|total_reviews|\n",
      "+----------------+---------------+-------------+\n",
      "|          461198|         297940|      1000000|\n",
      "+----------------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, countDistinct\n",
    "\n",
    "dfOverallStats = dfProductReview.agg(countDistinct(\"customer_id\").alias(\"unique_customers\"), \\\n",
    "                    countDistinct(\"product_id\").alias(\"unique_products\"), \\\n",
    "                    count(col=\"review_id\").alias(\"total_reviews\")) \\\n",
    "\n",
    "dfOverallStats.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For user-review distribution, you are asked to find out:\n",
    "\n",
    "* the largest number of reviews published by a single user\n",
    "* the top 10 users ranked by the number of reviews they publish\n",
    "* the median number of reviews published by a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Reviewer:\n",
      "+-----------+-------------+\n",
      "|customer_id|total_reviews|\n",
      "+-----------+-------------+\n",
      "|   38214553|         1497|\n",
      "+-----------+-------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Top 10 Reviewers:\n",
      "+-----------+-------------+\n",
      "|customer_id|total_reviews|\n",
      "+-----------+-------------+\n",
      "|   38214553|         1497|\n",
      "|   15536614|         1224|\n",
      "|   18116317|         1053|\n",
      "|    7080939|          921|\n",
      "|   14539589|          723|\n",
      "|   42836721|          652|\n",
      "|   47924228|          604|\n",
      "|   15725862|          594|\n",
      "|   47423754|          558|\n",
      "|   50736950|          513|\n",
      "+-----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import count\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "dfUserReviewCounts = helper.distributionStats(dfRecords=dfProductReview.select(\"customer_id\", \"review_id\"), \\\n",
    "                                              partitionBy=\"customer_id\",countBy=\"review_id\", \\\n",
    "                                              returnCountName=\"total_reviews\")\n",
    "print(\"Top Reviewer:\")\n",
    "dfUserReviewCounts.show(1)\n",
    "print(\"Top 10 Reviewers:\")\n",
    "dfUserReviewCounts.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median number of 1.0 reviews published by user\n"
     ]
    }
   ],
   "source": [
    "# median reviews \n",
    "# no median finder in spark... do we need to implement using RDD?\n",
    "\n",
    "user_review_median=dfUserReviewCounts.approxQuantile(\"total_reviews\", [0.50], 0)[0]\n",
    "print(\"median number of {0} reviews published by user\".format(user_review_median))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For product-review distribution, you are asked to find out:\n",
    "    \n",
    "* the largest number of reviews written for a single product\n",
    "* the top 10 products ranked by the number of reviews they have\n",
    "* the median number of reviews a product has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Product By Review:\n",
      "+----------+-------------+\n",
      "|product_id|total_reviews|\n",
      "+----------+-------------+\n",
      "|B00MIA0KGY|         2699|\n",
      "+----------+-------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Top 10 Products by Reviews:\n",
      "+----------+-------------+\n",
      "|product_id|total_reviews|\n",
      "+----------+-------------+\n",
      "|B00MIA0KGY|         2699|\n",
      "|B00NEJ7MMI|         2420|\n",
      "|B00MRHANNI|         1513|\n",
      "|B00H3GZMIE|         1277|\n",
      "|B00MU79IL8|         1172|\n",
      "|B00UCFVIDQ|         1114|\n",
      "|B00KLF5J64|         1038|\n",
      "|B00EDY5KTA|         1008|\n",
      "|B00NQKWAIQ|          997|\n",
      "|B00007KWHG|          826|\n",
      "+----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfProductReviewCounts = helper.distributionStats(dfRecords=dfProductReview.select(\"product_id\", \"review_id\"), \\\n",
    "                                              partitionBy=\"product_id\",countBy=\"review_id\", \\\n",
    "                                              returnCountName=\"total_reviews\")\n",
    "print(\"Top Product By Review:\")\n",
    "dfProductReviewCounts.show(1)\n",
    "print(\"Top 10 Products by Reviews:\")\n",
    "dfProductReviewCounts.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median number of 1 reviews per product\n"
     ]
    }
   ],
   "source": [
    "# median reviews \n",
    "# no median finder in spark... do we need to implement using RDD?\n",
    "\n",
    "product_review_median=int(dfProductReviewCounts.approxQuantile(\"total_reviews\", [0.5], 0)[0])\n",
    "print(\"median number of {0} reviews per product\".format(product_review_median))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage Two: Filtering Unwanted Data\n",
    "\n",
    "filter reviews based on length, reviewer and product feature. In particular, the following reviews should be removed:\n",
    "\n",
    "* reviews with less than two sentences in the review body.\n",
    "* reviews published by users with less than median number of reviews published\n",
    "* reviews from products with less than median number of reviews received\n",
    "\n",
    "NOTE: Sentence Segmentation Using: NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows before filter: 999701\n",
      "+-----------+--------------+----------+--------------------+----------------+-----------+-------------+-----------+--------------------+--------------------+-----------+\n",
      "|customer_id|     review_id|product_id|       product_title|product_category|star_rating|helpful_votes|total_votes|     review_headline|         review_body|review_date|\n",
      "+-----------+--------------+----------+--------------------+----------------+-----------+-------------+-----------+--------------------+--------------------+-----------+\n",
      "|   27664622|R3LGC3EKEG84PX|B00B6QXN6U|Same Trailer Diff...|           Music|          5|            0|          0|A new fave in our...|This is the album...| 2015-08-31|\n",
      "+-----------+--------------+----------+--------------------+----------------+-----------+-------------+-----------+--------------------+--------------------+-----------+\n",
      "only showing top 1 row\n",
      "\n",
      "number of rows post filter: 329468\n"
     ]
    }
   ],
   "source": [
    "# reviews with less than 2 sentences in review_body\n",
    "# convert to RDD and carry out a filter to remove rows with less than 2 sentences \n",
    "\n",
    "print(\"number of rows before filter: {0}\".format(dfFilteredReviews.count()))\n",
    "\n",
    "dfFilteredReviews = dfFilteredReviews.filter(helper.FilterSentences('review_body'))\n",
    "\n",
    "#reviewRdd = dfProductReview.rdd.map(list).filter(helper.FilterSentences)\n",
    "#print(reviewRdd.take(1))\n",
    "# convert back to DF \n",
    "#dfFilteredReviews = spark.createDataFrame(reviewRdd, aws_product_review_schema_limited)\n",
    "#dfFilteredReviews = reviewRdd.toDF(schema=aws_product_review_schema_limited)\n",
    "dfFilteredReviews.show(1)\n",
    "dfFilteredReviews.cache()\n",
    "\n",
    "print(\"number of rows post filter: {0}\".format(dfFilteredReviews.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows before filter: 329468\n",
      "number of rows post filter: 329468\n"
     ]
    }
   ],
   "source": [
    "# user review filter \n",
    "print(\"number of rows before filter: {0}\".format(dfFilteredReviews.count()))\n",
    "\n",
    "window = Window.partitionBy(\"customer_id\")\n",
    "dfFilteredReviews = dfFilteredReviews \\\n",
    "    .withColumn(\"review_count\", count(\"review_id\") \\\n",
    "    .over(window)) \\\n",
    "    .filter(col(\"review_count\") >= user_review_median) \\\n",
    "    .drop(\"review_count\")\n",
    "\n",
    "print(\"number of rows post filter: {0}\".format(dfFilteredReviews.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows before filter: 329468\n",
      "number of rows post filter: 329468\n"
     ]
    }
   ],
   "source": [
    "# product review filter\n",
    "print(\"number of rows before filter: {0}\".format(dfFilteredReviews.count()))\n",
    "\n",
    "window = Window.partitionBy(\"product_id\")\n",
    "dfFilteredReviews = dfFilteredReviews \\\n",
    "    .withColumn(\"review_count\", count(\"review_id\") \\\n",
    "    .over(window)) \\\n",
    "    .filter(col(\"review_count\") >= product_review_median) \\\n",
    "    .drop(\"review_count\")\n",
    "\n",
    "print(\"number of rows post filter: {0}\".format(dfFilteredReviews.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+----------+--------------------+----------------+-----------+-------------+-----------+--------------------+--------------------+-----------+\n",
      "|customer_id|     review_id|product_id|       product_title|product_category|star_rating|helpful_votes|total_votes|     review_headline|         review_body|review_date|\n",
      "+-----------+--------------+----------+--------------------+----------------+-----------+-------------+-----------+--------------------+--------------------+-----------+\n",
      "|   16615744|R36G0ETK84RMNN|5552936752|Scherrer/Fritz: S...|           Music|          4|            1|          1|Swiss Orchestral ...|Little is known a...| 2015-08-08|\n",
      "|   40083442| R6A3LEKK38HG6|B0000004IT|        Singles 1-12|           Music|          5|            0|          0| Melvins Starter Kit|Some might say, i...| 2014-07-03|\n",
      "|   20890474|R3RQWT6V0NHDSY|B0000005PU|        Mi Vida Loca|           Music|          4|            2|          2|    Delightful Music|Gaffney was a won...| 2014-06-15|\n",
      "|   45088304|R2HJIAXL0Z96O1|B0000006NP|   Moments Like This|           Music|          5|            0|          0|in Washington DC ...|I met C.B. in Was...| 2015-05-12|\n",
      "|   14475044|R35QAMR9V34ERJ|B0000006O6|       Heatin System|           Music|          3|            7|          7|Not the Recording...|This is a review ...| 2014-06-02|\n",
      "+-----------+--------------+----------+--------------------+----------------+-----------+-------------+-----------+--------------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfFilteredReviews.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Number of Rows before cleanup: 1000000\n",
      "Number of rows after all filters applied: 329468\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Number of Rows before cleanup: {0}\".format(dfProductReview.count()))\n",
    "print(\"Number of rows after all filters applied: {0}\".format(dfFilteredReviews.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[customer_id: string, review_id: string, product_id: string, product_title: string, product_category: string, star_rating: int, helpful_votes: int, total_votes: int, review_headline: string, review_body: string, review_date: date]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFilteredReviews.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After filtering out the above, find out:\n",
    "\n",
    "* top 10 users ranked by median number of sentences in the reviews they have published\n",
    "* top 10 products ranked by median number of sentences in the reviews they have received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+\n",
      "|customer_id|median_sents|\n",
      "+-----------+------------+\n",
      "|   41838529|         984|\n",
      "|   51970720|         454|\n",
      "|   51865782|         440|\n",
      "|   52672392|         311|\n",
      "|   50595705|         211|\n",
      "|   17821650|         183|\n",
      "|   36934717|         171|\n",
      "|   29705444|         163|\n",
      "|   13551370|         157|\n",
      "|   14678937|         155|\n",
      "+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# top 10 users ranked by median number of sentences in the reviews they have published\n",
    "#dfTop10UsersBySents = helper.getTopBySentNumber(dfRecords=dfFilteredReviews, topnCol=\"customer_id\", \\\n",
    "#                                                textCol=\"review_body\",n=10)\n",
    "\n",
    "dfTop10UsersBySents = helper.getTopBySentMedian(dfRecords=dfFilteredReviews,partitionBy=\"customer_id\", \\\n",
    "                                                textCol=\"review_body\",medianColName=\"median_sents\",n=10)\n",
    "#dfTop10UsersBySents.select(\"customer_id\",\"product_id\",\"product_title\",\"review_body\",\"median_sents\").show(10)\n",
    "dfTop10UsersBySents.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|product_id|median_sents|\n",
      "+----------+------------+\n",
      "|B00LTQ5EVY|         984|\n",
      "|B00000411D|         302|\n",
      "|B000001G8Z|         295|\n",
      "|B002QZPVBK|         289|\n",
      "|B00HSP0P0U|         274|\n",
      "|B005MJVMO2|         274|\n",
      "|B005OZBTWE|         273|\n",
      "|B000005986|         271|\n",
      "|B000004119|         269|\n",
      "|B000003425|         266|\n",
      "+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# top 10 products ranked by median number of sentences in the reviews they have received\n",
    "#dfTop10ProductsBySents = helper.getTopBySentNumber(dfRecords=dfFilteredReviews, topnCol=\"product_id\", \\\n",
    "#                                                textCol=\"review_body\",n=10)\n",
    "dfTop10ProductsBySents = helper.getTopBySentMedian(dfRecords=dfFilteredReviews,partitionBy=\"product_id\", \\\n",
    "                                                textCol=\"review_body\",medianColName=\"median_sents\",n=10)\n",
    "\n",
    "dfTop10ProductsBySents.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the cleaned and filtered dataframe to file system \n",
    "\n",
    "#dfFilteredReviews.coalesce(1).write.format(\"parquet\") \\\n",
    "#    .option(\"header\", \"true\").saveAsTable('filteredReviews',mode=\"overwrite\")\n",
    "dfFilteredReviews.coalesce(1).write.csv(\"../output\",mode=\"overwrite\",header=True,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3 Similarity analysis with Sentence Embedding\n",
    "\n",
    "perform similarity analysis on the review sentences. The analysis involves segmenting review body into multiple sentences; encoding each sentence as vector so that the distance between pair of sentences can be computed.\n",
    "\n",
    "### Positive vs. Negative Reviews\n",
    "\n",
    "* pick a product from the top 10 products in stage 1\n",
    "* Create a positive and negative class of reviews using the rating \n",
    "    - Positive Class - rate >=4 \n",
    "    - Negative Class - rate <= 2\n",
    "    - for each review, extracting the review body part and segment it into multiple sentences.\n",
    "    - encode the sentences using google universal encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the base/filtered dataset created earlier \n",
    "filtered_data = \"../output/part-*.csv\"\n",
    "dfBaseDataset = spark.read.csv(filtered_data,header=True,sep=\"\\t\",schema=aws_product_review_schema_limited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product from top 10 by review number \n",
    "base_product_id = \"B00MIA0KGY\"\n",
    "\n",
    "dfPositiveClass = dfBaseDataset.where((col(\"product_id\") == base_product_id) & (col(\"star_rating\") >= 4))\n",
    "dfNegativeClass = dfBaseDataset.where((col(\"product_id\") == base_product_id) & (col(\"star_rating\") <= 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of positives: 110098\n",
      "number of positives: 214\n",
      "number of negatives: 16\n"
     ]
    }
   ],
   "source": [
    "print(\"number of positives: {0}\".format(dfBaseDataset.count()))\n",
    "print(\"number of positives: {0}\".format(dfPositiveClass.count()))\n",
    "print(\"number of negatives: {0}\".format(dfNegativeClass.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for each review, extract the review body part and segment it into multiple sentences\n",
    "# extract the positive sentences\n",
    "dfPosSents = dfPositiveClass.select(\"review_id\",\"review_body\") \\\n",
    "    .withColumn(\"sentences\", helper.GenerateSentences(\"review_body\")) \\\n",
    "    .select(\"review_id\", F.explode_outer(\"sentences\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the sentences - similar to flatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the negative sentences\n",
    "dfNegSents = dfNegativeClass.select(\"review_id\",\"review_body\") \\\n",
    "    .withColumn(\"sentences\", helper.GenerateSentences(\"review_body\")) \\\n",
    "    .select(\"review_id\", F.explode_outer(\"sentences\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sententences extracted: 1324\n",
      "Negative sententences extracted: 139\n",
      "+--------------+--------------------+\n",
      "|     review_id|                 col|\n",
      "+--------------+--------------------+\n",
      "|R338L3ESXHT0XJ|                Wow!|\n",
      "|R338L3ESXHT0XJ|The absolutely pe...|\n",
      "|R338L3ESXHT0XJ|She has never sou...|\n",
      "|R338L3ESXHT0XJ|I would not be su...|\n",
      "|R338L3ESXHT0XJ|Impossible to pic...|\n",
      "+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------+--------------------+\n",
      "|     review_id|                 col|\n",
      "+--------------+--------------------+\n",
      "|R2D3O3SJ7R34VV|         Dullsville.|\n",
      "|R2D3O3SJ7R34VV|All the wrong son...|\n",
      "|R2D3O3SJ7R34VV|Streisand even  h...|\n",
      "|R2D3O3SJ7R34VV|             BORING.|\n",
      "|R2D3O3SJ7R34VV|        No artistry.|\n",
      "+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive sententences extracted: {0}\".format(dfPosSents.count()))\n",
    "print(\"Negative sententences extracted: {0}\".format(dfNegSents.count()))\n",
    "\n",
    "dfPosSents.show(5)\n",
    "dfNegSents.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the sentences - google universal encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
